{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54fc81e5",
   "metadata": {},
   "source": [
    "# FASTROLL\n",
    "\n",
    "TODO: write smt about project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c5d4e",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "We decided to gather data from 3 different sources.\n",
    "1) Kaggle data set https://www.kaggle.com/milesh1/35-million-chess-games\n",
    "2) Random moves\n",
    "3) Random FEN\n",
    "\n",
    "Each set of data consist of 100,000 data points:\n",
    "    FEN record -> Win or Lose\n",
    "\n",
    "Kaggle set was genereted by taking pre-existing games, then we would extract each state from a game in FEN.\n",
    "Random moves was done in similar maner, only the games were playout randomly at time of gerneration.\n",
    "Random FEN is just a random placement of the pieces.\n",
    "\n",
    "Win or Lose was obtained by evaluating each FEN by stockfish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f7f96",
   "metadata": {},
   "source": [
    "## Imports and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e4bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as sopt\n",
    "import graphviz\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import Iterable\n",
    "import chess\n",
    "from chess import Board\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def valign(v):\n",
    "    \"Align vector vertically.\"\n",
    "    return v.reshape(-1, 1)\n",
    "\n",
    "\n",
    "def slog(x):\n",
    "    \"Numerically stable logarithm.\"\n",
    "    return np.log(x + 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe7f27",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05251b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"Numerically stable sigmoid function.\"\n",
    "\n",
    "    def _positive_sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _negative_sigmoid(x):\n",
    "        exp = np.exp(x)\n",
    "        return exp / (exp + 1)\n",
    "\n",
    "    positive = x >= 0\n",
    "    negative = ~positive\n",
    "    result = np.empty_like(x)\n",
    "    result[positive] = _positive_sigmoid(x[positive])\n",
    "    result[negative] = _negative_sigmoid(x[negative])\n",
    "    return result\n",
    "\n",
    "\n",
    "def logreg(X, Theta):\n",
    "    return sigmoid(X @ Theta)\n",
    "\n",
    "\n",
    "def logreg_loss(Theta, X, Y, alpha):\n",
    "    \"Logistic regression cost suitable for use with fmin_l_bfgs.\"\n",
    "\n",
    "    # Reshape Theta into a column vector - lBFGS gives us a flat array\n",
    "    ThetaR = valign(Theta)\n",
    "\n",
    "    hx = logreg(X, ThetaR)\n",
    "    nll = -np.sum(Y.T @ slog(hx) + (1-Y).T @ slog(1-hx)) + alpha * (ThetaR @ ThetaR.T)\n",
    "    grad = X.T @ (hx - Y)\n",
    "\n",
    "    # Reshape grad into the shape of Theta, for fmin_l_bfsgb to work\n",
    "    return nll, grad.reshape(Theta.shape)\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, X, Y, alpha=0, theta: np.ndarray = None):\n",
    "        if theta is not None:\n",
    "            self.theta = theta\n",
    "            return\n",
    "\n",
    "        assert X.shape[0] == Y.shape[0], \"shape mismatch!\"\n",
    "        assert Y.shape[1] == 1, \"expected a vertical vector for Y!\"\n",
    "\n",
    "        # Call a solver\n",
    "        self.theta = sopt.fmin_l_bfgs_b(\n",
    "            lambda Theta: logreg_loss(Theta, X, Y, alpha), np.zeros(X.shape[1])\n",
    "        )[0]\n",
    "\n",
    "    def error(self, X, Y):\n",
    "        \"Return percentage of failed predictions.\"\n",
    "        assert X.shape[0] == Y.shape[0], \"shape mismatch!\"\n",
    "        assert Y.shape[1] == 1, \"expected a vertical vector for Y!\"\n",
    "\n",
    "        preds = valign(np.round(self.__call__(X)).astype(int))\n",
    "        return np.sum(np.abs(Y - preds)) / len(Y)\n",
    "\n",
    "    def __call__(self, X):\n",
    "        assert X.shape[1] == self.theta.shape[0], \"theta shape mismatch!\"\n",
    "        return logreg(X, self.theta)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf9342",
   "metadata": {},
   "source": [
    "### Forests implemenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626626d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(counts):\n",
    "    P = counts/(np.sum(counts))\n",
    "    return -np.sum(P*np.log2(P + 1e-10))\n",
    "\n",
    "\n",
    "def gini(counts):\n",
    "    return 1 - np.sum((counts / np.sum(counts))**2)\n",
    "\n",
    "\n",
    "def mean_err_rate(counts):\n",
    "    return 1 - np.max(counts)/np.sum(counts)\n",
    "\n",
    "\n",
    "class AbstractSplit:\n",
    "    \"\"\"Split the examples in a tree node according to a criterion.\"\"\"\n",
    "\n",
    "    def __init__(self, attr):\n",
    "        self.attr = attr\n",
    "        self.purity_gain = 0.0\n",
    "\n",
    "    def mean_purity(self, df, purity_function):\n",
    "        \"\"\"Return mean purity across all split's children.\"\"\"\n",
    "        def purity(child):\n",
    "            return purity_function(child['target'].value_counts()) * len(child)\n",
    "        return sum(purity(child) for _, child in df.groupby(self.attr)) / len(df)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"Return the subtree corresponding to x.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build_subtrees(self, df, subtree_kwargs):\n",
    "        \"\"\"Recuisively build the subtrees.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def iter_subtrees(self):\n",
    "        \"\"\"Return an iterator over subtrees.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def add_to_graphviz(self, dot):\n",
    "        \"\"\"Add the split to the graphviz vizalization.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.__class__.__name__}: {self.attr}\"\n",
    "\n",
    "\n",
    "def get_split(df, purity_function=entropy, nattrs=None):\n",
    "    target_value_counts = df[\"target\"].value_counts()\n",
    "    if len(target_value_counts) == 1:\n",
    "        return None\n",
    "\n",
    "    possible_splits = [attr for attr in df.columns if attr !=\n",
    "                       'target' and len(df[attr].unique()) > 1]\n",
    "    if not possible_splits:\n",
    "        return None\n",
    "\n",
    "    # Random Forest support\n",
    "    # restrict possible_splits to a few radomly selected attributes\n",
    "    if nattrs is not None:\n",
    "        random.shuffle(possible_splits)\n",
    "        possible_splits = possible_splits[:nattrs]\n",
    "\n",
    "    splits = [\n",
    "        CategoricalMultivalueSplit(attr)\n",
    "        for attr in possible_splits\n",
    "    ]\n",
    "\n",
    "    best_split = min(splits, key=lambda s: s.mean_purity(df, purity_function))\n",
    "    base_purity = purity_function(target_value_counts)\n",
    "    best_split.purity_gain = base_purity - \\\n",
    "        best_split.mean_purity(df, purity_function)\n",
    "    if best_split.purity_gain >= 0:\n",
    "        return best_split\n",
    "    return None\n",
    "\n",
    "\n",
    "class CategoricalMultivalueSplit(AbstractSplit):\n",
    "    def __call__(self, x):\n",
    "        a = x[self.attr]\n",
    "        if a in self.subtrees:\n",
    "            return self.subtrees[a]\n",
    "        return None\n",
    "\n",
    "    def build_subtrees(self, df, subtree_kwargs):\n",
    "        self.subtrees = {}\n",
    "        for group_name, group_df in df.groupby(self.attr):\n",
    "            child = Tree(group_df, **subtree_kwargs)\n",
    "            self.subtrees[group_name] = child\n",
    "\n",
    "    def iter_subtrees(self):\n",
    "        return self.subtrees.values()\n",
    "\n",
    "    def add_to_graphviz(self, dot, parent, print_info):\n",
    "        for split_name, child in self.subtrees.items():\n",
    "            child.add_to_graphviz(dot, print_info)\n",
    "            dot.edge(f\"{id(parent)}\", f\"{id(child)}\", label=f\"{split_name}\")\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self, df, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # Technicality:\n",
    "        # We need to let subtrees know about all targets to properly color nodes\n",
    "        # We pass this in subtree arguments.\n",
    "        if \"all_targets\" not in kwargs:\n",
    "            kwargs[\"all_targets\"] = sorted(df[\"target\"].unique())\n",
    "\n",
    "        # Save keyword arguments to build subtrees\n",
    "        kwargs_orig = dict(kwargs)\n",
    "\n",
    "        # Get kwargs we know about, remaning ones will be used for splitting\n",
    "        self.all_targets = kwargs.pop(\"all_targets\")\n",
    "\n",
    "        # Save debug info for visualization\n",
    "        # Debugging tip: contents of self.info are printed in tree visualizations!\n",
    "        self.counts = df[\"target\"].value_counts()\n",
    "        self.info = {\n",
    "            \"num_samples\": len(df),\n",
    "            \"entropy\": entropy(self.counts),\n",
    "            \"gini\": gini(self.counts),\n",
    "        }\n",
    "\n",
    "        self.split = get_split(df, **kwargs)\n",
    "        if self.split:\n",
    "            self.split.build_subtrees(df, kwargs_orig)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return self.get_target_distribution(sample).idxmax()\n",
    "\n",
    "    def prune_confidence(self):\n",
    "        if self.split is None:\n",
    "            return 0.0\n",
    "\n",
    "        z = 1.96  # 95% confidence level\n",
    "\n",
    "        def confidence(counts):\n",
    "            err = mean_err_rate(counts)\n",
    "            return err + z * np.sqrt(err*(1-err)/np.sum(counts))\n",
    "\n",
    "        node_confidence = self.info['confidence_interval'] = confidence(\n",
    "            self.counts)\n",
    "        if any(node_confidence <= tree.prune_confidence() for tree in self.split.iter_subtrees()):\n",
    "            self.split = None\n",
    "        return node_confidence\n",
    "\n",
    "    def leaf(self, sample):\n",
    "        if self.split is None:\n",
    "            return self\n",
    "        subtree = self.split(sample)\n",
    "        return subtree.leaf(sample) if subtree else self\n",
    "\n",
    "    def measure_purity_gain(self, attr):\n",
    "        if self.split == None:\n",
    "            return 0.0\n",
    "        purity = sum(subtree.measure_purity_gain(attr)\n",
    "                     for subtree in self.split.iter_subtrees())\n",
    "        if self.split.attr == attr:\n",
    "            purity += self.split.purity_gain\n",
    "        return purity\n",
    "\n",
    "    def get_target_distribution(self, sample):\n",
    "        # descend into subtrees and return the leaf target distribution\n",
    "        return self.leaf(sample).counts\n",
    "\n",
    "    def draw(self, print_info=True):\n",
    "        dot = graphviz.Digraph()\n",
    "        self.add_to_graphviz(dot, print_info)\n",
    "        return dot\n",
    "\n",
    "    def add_to_graphviz(self, dot, print_info):\n",
    "        freqs = self.counts / self.counts.sum()\n",
    "        freqs = dict(freqs)\n",
    "        colors = []\n",
    "        freqs_info = []\n",
    "        for i, c in enumerate(self.all_targets):\n",
    "            freq = freqs.get(c, 0.0)\n",
    "            if freq > 0:\n",
    "                colors.append(f\"{i%9 + 1};{freq}\")\n",
    "                freqs_info.append(f\"{c}:{freq:.2f}\")\n",
    "        colors = \":\".join(colors)\n",
    "        labels = [\" \".join(freqs_info)]\n",
    "        if print_info:\n",
    "            for k, v in self.info.items():\n",
    "                labels.append(f\"{k} = {v}\")\n",
    "        if self.split:\n",
    "            labels.append(f\"split by: {self.split.attr}\")\n",
    "        dot.node(\n",
    "            f\"{id(self)}\",\n",
    "            label=\"\\n\".join(labels),\n",
    "            shape=\"box\",\n",
    "            style=\"striped\",\n",
    "            fillcolor=colors,\n",
    "            colorscheme=\"set39\",\n",
    "        )\n",
    "        if self.split:\n",
    "            self.split.add_to_graphviz(dot, self, print_info)\n",
    "\n",
    "\n",
    "def error(tree, test: pd.DataFrame):\n",
    "    predcts = test.apply(lambda row: tree(row), axis=1).values\n",
    "    targets = test['target'].values\n",
    "    return sum(predcts[i] != targets[i] for i in range(len(test))) / len(test)\n",
    "\n",
    "\n",
    "class RandomForest(list):\n",
    "    def __init__(self, training_set, target_column_name=\"target\", nattrs=1, size=0, pruning=False):\n",
    "        self.train = training_set.rename(\n",
    "            columns={target_column_name: \"target\"}, inplace=False)\n",
    "        self.targets = target_column_name\n",
    "        self.nattrs = nattrs\n",
    "\n",
    "        # Initialize with size\n",
    "        for _ in range(size):\n",
    "            self.add_tree()\n",
    "\n",
    "        if pruning:\n",
    "            for tree in self:\n",
    "                tree.prune_confidence()\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        votes = [tree(sample) for tree in self]\n",
    "        return pd.Series(data=votes).value_counts().idxmax()\n",
    "\n",
    "    def add_tree(self):\n",
    "        bootstrap = self.train.sample(frac=1.0, replace=True)\n",
    "        tree = Tree(bootstrap, nattrs=self.nattrs)\n",
    "        self.append(tree)\n",
    "\n",
    "    def forest_error(self, test):\n",
    "        return error(self, test.rename(columns={self.targets: \"target\"}, inplace=False))\n",
    "\n",
    "    def trees_agreement(self, test_df):\n",
    "        agreement = 0\n",
    "        for _, sample in test_df.iterrows():\n",
    "            votes = [tree(sample) for tree in self]\n",
    "            pred = pd.Series(data=votes).value_counts().idxmax()\n",
    "            agreement += np.sum(pred == votes)/len(votes)\n",
    "        return agreement/len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b098e30",
   "metadata": {},
   "source": [
    "### Data and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0646b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df   = pd.read_csv('../datasets/kaggle.csv')\n",
    "random_df   = pd.read_csv('../datasets/random.csv')\n",
    "rollouts_df = pd.read_csv('../datasets/rollouts.csv')\n",
    "kaggle_df.columns   = [\"FEN\", \"Winner\"]\n",
    "random_df.columns   = [\"FEN\", \"Winner\"]\n",
    "rollouts_df.columns = [\"FEN\", \"Winner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chess_pieces = dict(zip(\".prnbqkPRNBQK\", range(13)))\n",
    "weights = {\n",
    "    \"P\": 1, \"N\": 3, \"B\": 3,\n",
    "    \"R\": 5, \"Q\": 9, \"K\": 0\n",
    "}\n",
    "\n",
    "\n",
    "def squares(fen: str):\n",
    "    \"\"\"Encode game state as a vector of squares,\n",
    "    where each square is associated with the piece\n",
    "    that it is occupied by or with zero otherwise.\"\"\"\n",
    "    board = str(Board(fen))\n",
    "    return np.array([chess_pieces[p] for p in board if p not in '\\n '])\n",
    "\n",
    "\n",
    "def one_hot_enc_piece(piece: str):\n",
    "    \"\"\"One-hot encode chess piece as 12-dimensional (6 types of pieces,\n",
    "    2 colors each) vector v, where \\n\n",
    "    v_{0}  indicates black pawn, \\n\n",
    "    v_{1}  indicates black rook, \\n\n",
    "    v_{2}  indicates black knight, \\n\n",
    "    v_{3}  indicates black bishop, \\n\n",
    "    v_{4}  indicates black queen, \\n\n",
    "    v_{5}  indicates black king, \\n\n",
    "    v_{6}  indicates white pawn, \\n\n",
    "    v_{7}  indicates white rook, \\n\n",
    "    v_{8}  indicates white knight, \\n\n",
    "    v_{9}  indicates white bishop, \\n\n",
    "    v_{10} indicates white queen, \\n\n",
    "    v_{11} indicates white king.\n",
    "    \"\"\"\n",
    "    if piece == '.':\n",
    "        return np.zeros(len(chess_pieces) - 1)\n",
    "    index = chess_pieces[piece] - 1\n",
    "    zeros_before = [0] * index\n",
    "    # Why -2:\n",
    "    # The 1st -1 becasue we have to count in dot at the beginning of `chess_pieces`.\n",
    "    # The 2nd -1 to get index of last piece.\n",
    "    zeros_after = [0] * (len(chess_pieces) - 2 - index)\n",
    "    return np.array(zeros_before + [1] + zeros_after)\n",
    "\n",
    "\n",
    "def binary(fen: str):\n",
    "    \"\"\"Encode game state as a 773-dimensional vector v, where for i in\n",
    "    {0, 12, ..., 756}\n",
    "    v_{i}   indicates that there's black pawn on square floor(i/12), \\n\n",
    "    v_{i+1} indicates that there's black rook on square floor(i/12), \\n\n",
    "    v_{i+2} indicates that there's black knight on square floor(i/12), \\n\n",
    "    v_{i+3} indicates that there's black bishop on square floor(i/12), \\n\n",
    "    v_{i+4} indicates that there's black queen on square floor(i/12), \\n\n",
    "    v_{i+5} indicates that there's black king on square floor(i/12), \\n\n",
    "    v_{i+6}  indicates that there's white pawn on square floor(i/12), \\n\n",
    "    v_{i+7}  indicates that there's white rook on square floor(i/12), \\n\n",
    "    v_{i+8}  indicates that there's white knight on square floor(i/12), \\n\n",
    "    v_{i+9}  indicates that there's white bishop on square floor(i/12), \\n\n",
    "    v_{i+10} indicates that there's white queen on square floor(i/12), \\n\n",
    "    v_{i+11} indicates that there's white king on square floor(i/12). \\n\n",
    "\n",
    "    Squares are ordered in row-major way from top left (A8) to bottom right (H1). \\n\n",
    "\n",
    "    v_768 indicates player to move, \\n\n",
    "    v_769 indicates whether black has kingside castling right, \\n\n",
    "    v_770 indicates whether black has queenside castling right, \\n\n",
    "    v_771 indicates whether white has kingside castling right, \\n\n",
    "    v_772 indicates whether white has queenside castling right. \\n\n",
    "\n",
    "    \\\"indicates\\\" means \\\"is set to 0 or 1 depending on whether condition is\n",
    "    false or true\\\".\"\"\"\n",
    "    board = Board(fen)\n",
    "    encoding = np.array([])\n",
    "    for p in str(board):\n",
    "        if p in '\\n ':\n",
    "            continue\n",
    "        encoding = np.hstack((encoding, one_hot_enc_piece(p)))\n",
    "    encoding = np.hstack((encoding, int(board.turn)))\n",
    "    castling_rights = []\n",
    "    for castling_rook_pos in [chess.BB_H8, chess.BB_A8, chess.BB_H1, chess.BB_A1]:\n",
    "        castling_rights.append(\n",
    "            int(bool(board.castling_rights & castling_rook_pos)))\n",
    "    encoding = np.hstack((encoding, np.array(castling_rights)))\n",
    "    return encoding\n",
    "\n",
    "\n",
    "def advantage(fen: str):\n",
    "    \"\"\"Calculate player advantage based only on moves and pieces they possess.\n",
    "\n",
    "        - move advantage is the difference between the number of moves\n",
    "        available to each player\n",
    "        - material advantage is the difference of sums of weights of all the pieces\n",
    "        on the board\n",
    "\n",
    "    Values are positive if White has the advantage and negative otherwise.\n",
    "    \"\"\"\n",
    "    board = Board(fen)\n",
    "    material_advantage = sum(\n",
    "        weights[p] if p in weights else -weights[p.upper()]\n",
    "        for p in str(board) if p not in '\\n .'\n",
    "    )\n",
    "    board.turn = 1\n",
    "    move_advantage = len(list(board.legal_moves))\n",
    "    board.turn = 0\n",
    "    move_advantage -= len(list(board.legal_moves))\n",
    "    return np.array([move_advantage, material_advantage])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
